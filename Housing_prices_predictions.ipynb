{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93cf3df1-c028-4115-acb8-2d352961542b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h1>Download and Load Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b8fb2e-ed0c-4e4e-90b9-49634f93f987",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from scripts.data_fetch import fetch_data, load_data\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from zlib import crc32\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "HOUSING_PATH = os.path.join(\"./DATASETS\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "data = {'data_path': HOUSING_PATH, 'data_url': HOUSING_URL, 'data_file_name': 'housing.tgz'}\n",
    "fetch_data(data)\n",
    "housing_csv = load_data(HOUSING_PATH, 'housing.csv')\n",
    "housing_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4552865b-8d29-4f90-a7af-01e9f0a53b1b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h1> Pre-processing data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef4b337-dc9f-4065-aff3-e8b2d5e76235",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def split_train_test(data, test_ratio):\n",
    "    '''useful but not allow reproductible data.Generated train data cannot be the same in other training'''\n",
    "    shuffle_indices = np.random.permutation(len(data))\n",
    "    test_indices_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffle_indices[:test_indices_size]\n",
    "    train_indices = shuffle_indices[test_indices_size:]\n",
    "    return data.iloc[train_indices] , data.iloc[test_indices]\n",
    "\n",
    "def test_set_check(identifier, test_ratio):\n",
    "    return crc32(np.int64(identifier)) & 0xffffffff < test_ratio * 2**32\n",
    "\n",
    "def split_train_test_by_id(data, test_ratio, id_column):\n",
    "    '''useful for data seed . '''\n",
    "    ids = data[id_column]\n",
    "    in_test_set = ids.apply(lambda id_ : test_set_check(id_, test_ratio))\n",
    "    return data.loc[~in_test_set], data.loc[in_test_set]\n",
    "    \n",
    "housing_with_id = housing_csv.reset_index()\n",
    "train_data , test_data = split_train_test_by_id(housing_with_id, 0.2, 'index')\n",
    "\n",
    "housing_csv[\"income_cat\"] = pd.cut(housing_csv[\"median_income\"],\n",
    "                                   bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                                   labels=[1, 2, 3, 4, 5]\n",
    "                                  )\n",
    "housing_csv[\"income_cat\"].hist()\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index , test_index in split.split(housing_csv, housing_csv['income_cat']):\n",
    "    strat_train_set = housing_csv.loc[train_index]\n",
    "    strat_test_set = housing_csv.loc[test_index]\n",
    "    \n",
    "    \n",
    "print(strat_test_set['income_cat'].value_counts()/len(strat_test_set))\n",
    "print(housing_csv['income_cat'].value_counts()/len(housing_csv))\n",
    "\n",
    "for _set in (strat_train_set , strat_test_set):\n",
    "    _set.drop('income_cat', axis=1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9b9c13-bac0-4c4a-81b5-ffb07dfa631b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "housing_full_data = strat_train_set.copy()\n",
    "housing = strat_train_set.drop('median_house_value', axis=1)\n",
    "housing_labels = strat_train_set['median_house_value'].copy()\n",
    "\n",
    "housing_full_data.plot(kind='scatter' , \n",
    "             x='longitude', \n",
    "             y='latitude' , \n",
    "             alpha = 0.4 , \n",
    "             s=housing['population']/100,\n",
    "             c = 'median_house_value',\n",
    "             cmap = plt.get_cmap('jet'),\n",
    "             colorbar = True,\n",
    "             label ='population')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebd2b8d-7314-4ab0-b4e2-b31a36786b8b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "housing.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11433188-b5e7-48e2-84d6-763e2c9b1501",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "median = housing['total_bedrooms'].median()\n",
    "housing['total_bedrooms'].fillna(median, inplace=True)\n",
    "\n",
    "inputer = SimpleImputer(strategy='median')\n",
    "housing_num = housing.drop('ocean_proximity', axis=1)\n",
    "inputer.fit(housing_num)\n",
    "print(inputer.statistics_)\n",
    "print(housing_num.median().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8a2557-b8df-4d44-96b7-9aefa79b6dcb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "housing_cat = housing[['ocean_proximity']]\n",
    "housing_cat[:10]\n",
    "hot_encoder = OneHotEncoder()\n",
    "cat_encoder = hot_encoder.fit_transform(housing_cat)\n",
    "cat_encoder.toarray()\n",
    "\n",
    "class CombinedTransform(BaseEstimator , TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True):\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        rooms_ix , bedrooms_ix , population_ix, households_ix = 3,4,5,6\n",
    "        rooms_per_households = X[:, rooms_ix] / X[:, households_ix] \n",
    "        population_per_households = X[:, population_ix] / X[:, households_ix]\n",
    "        if self.add_bedrooms_per_room :\n",
    "            bedrooms_per_room = X[:,bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X,rooms_per_households , population_per_households, bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_households , population_per_households]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957fd4cb-6cbe-4efa-9377-e74997d7a13f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression , SGDRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#performing learning by LinearRgression , DecisionTreeRegression and SGDRegressor(Gradient Based Regression) \n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "('imputer_ext', SimpleImputer(strategy='median')),\n",
    "('attr_adder', CombinedTransform()),\n",
    "('attr_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "housing_pipeline = num_pipeline.fit_transform(housing_num)\n",
    "\n",
    "list_num = list(housing_num)\n",
    "housing_cats = ['ocean_proximity']\n",
    "\n",
    "perform_pipeline_column = ColumnTransformer([\n",
    "('num', num_pipeline, list_num),\n",
    "('cat', OneHotEncoder(), housing_cats)\n",
    "])\n",
    "\n",
    "class RegressionBasedType:\n",
    "    \n",
    "    ln_model = None\n",
    "    \n",
    "    def __init__(self, regression_type, data_train, data_train_labels, data_test, data_test_labels):\n",
    "        self.regression_type = regression_type #must be a class\n",
    "        self.data_train = data_train\n",
    "        self.data_train_labels = data_train_labels\n",
    "        self.data_test = data_test\n",
    "        self.data_test_labels = data_test_labels\n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "        self.ln_model = self.regression_type()\n",
    "        self.ln_model.fit(self.data_train, self.data_train_labels)\n",
    "        return self\n",
    "        \n",
    "    def test_return(self):\n",
    "        #data_test must be perform by ColumnTransformer pipeline and not contains y label\n",
    "        predicted_data = self.ln_model.predict(self.data_test)\n",
    "        return predicted_data , self.data_test_labels\n",
    "    \n",
    "    def metrics_error(self):\n",
    "        #performance measure used is root mean squrared error\n",
    "        predicted_data , data_labels = self.test_return()\n",
    "        mse = mean_squared_error(data_labels, predicted_data)\n",
    "        rmse = np.sqrt(mse)\n",
    "        return rmse\n",
    "        \n",
    "housing_prepared = perform_pipeline_column.fit_transform(housing)\n",
    "some_data_prepared = perform_pipeline_column.transform(housing.iloc[:5]) #use for test so not fit\n",
    "some_data_labels = housing_labels.iloc[:5] #use for test label\n",
    "\n",
    "LinearReg = RegressionBasedType(\n",
    "    regression_type=LinearRegression, \n",
    "    data_train=housing_prepared, \n",
    "    data_train_labels = housing_labels,\n",
    "    data_test=some_data_prepared,\n",
    "    data_test_labels = some_data_labels\n",
    ")\n",
    "\n",
    "DecisionTreeReg = RegressionBasedType(\n",
    "    regression_type=DecisionTreeRegressor, \n",
    "    data_train=housing_prepared, \n",
    "    data_train_labels = housing_labels,\n",
    "    data_test=some_data_prepared,\n",
    "    data_test_labels = some_data_labels\n",
    ")\n",
    "\n",
    "SGDReg = RegressionBasedType(\n",
    "    regression_type=SGDRegressor, \n",
    "    data_train=housing_prepared, \n",
    "    data_train_labels = housing_labels,\n",
    "    data_test=some_data_prepared,\n",
    "    data_test_labels = some_data_labels\n",
    ")\n",
    "\n",
    "\n",
    "LinearReg.train()\n",
    "DecisionTreeReg.train()\n",
    "SGDReg.train()\n",
    "linear_metrics_error = LinearReg.metrics_error()\n",
    "decision_metrics_error = DecisionTreeReg.metrics_error()\n",
    "sgd_metrics_error = SGDReg.metrics_error()\n",
    "print(linear_metrics_error)\n",
    "print(decision_metrics_error)\n",
    "print(sgd_metrics_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff9b963-8993-4a00-8ad7-9b6d29600c97",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h1>Wow, is this mean that DecisionTree Regression performs so good the learning ? Let's try cross validation &#128515;</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f6e833-00b4-4cc8-918c-75d53e0863c8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "linear_regression = LinearRegression()\n",
    "decision_tree = DecisionTreeRegressor()\n",
    "\n",
    "score1 = cross_val_score(\n",
    "    linear_regression, \n",
    "    housing_prepared, \n",
    "    housing_labels, \n",
    "    scoring='neg_mean_squared_error', \n",
    "    cv=10)\n",
    "\n",
    "score2 = cross_val_score(\n",
    "    decision_tree,\n",
    "    housing_prepared,\n",
    "    housing_labels,\n",
    "    scoring = 'neg_mean_squared_error',\n",
    "    cv = 10\n",
    "    )\n",
    "\n",
    "linear_squared_error = np.sqrt(-score1)\n",
    "tree_squared_error = np.sqrt(-score2)\n",
    "print('======>For Linear Regression')\n",
    "print(linear_squared_error.mean())\n",
    "print(linear_squared_error.std())\n",
    "print('=======> For Decision Tree Regression')\n",
    "print(tree_squared_error.mean())\n",
    "print(tree_squared_error.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d621a0b-c66d-42f6-a6e3-9b1cea9fcd89",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h1>Probally not. It performs so good the learning that we don't worry about overfiting &#128515;</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a9ce42-1adb-47f1-a9a0-4fc8011f1d50",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4821b3-43de-497d-8dd9-29f8b5e77ab2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
